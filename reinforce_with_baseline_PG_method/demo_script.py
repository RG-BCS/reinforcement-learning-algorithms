# -*- coding: utf-8 -*-
"""perceptron.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vBkRx3zcZqLB5_Zuq6uHAsPLXGc655Hl
"""

import gym
import numpy as np
import tensorflow as tf
from tensorflow import keras
from reinforce_with_baseline import evaluate_episode, train_policy_model
import matplotlib.pyplot as plt

# Set seed for reproducibility
seed = 65
np.random.seed(seed)
tf.random.set_seed(seed)

# Environment and model setup
env_name = "CartPole-v1"
n_inputs = 4
gamma = 0.99
n_episodes = 500

# Build the policy model
policy_model = keras.Sequential([
    keras.layers.InputLayer(shape=(n_inputs,)),
    keras.layers.Dense(5, activation='elu'),
    keras.layers.Dense(1, activation='sigmoid')
])

# Initial performance test
env = gym.make(env_name)
print("Evaluating untrained policy...")
initial_reward = evaluate_episode(policy_model, env)
print(f"Initial total reward: {initial_reward:.2f}")

# Training the policy using REINFORCE with baseline
print("\nTraining policy with REINFORCE + baseline...")
reward_history = train_policy_model(
    n_episodes=n_episodes,
    env_name=env_name,
    policy_model=policy_model,
    gamma=gamma
)

# Post-training evaluation
print("\nEvaluating trained policy...")
test_rewards = [evaluate_episode(policy_model, env) for _ in range(20)]
print(f"Final total reward (1 episode): {test_rewards[0]:.2f}")
print(f"Average reward over 20 test episodes: {np.mean(test_rewards):.2f}")

# Plot reward history
plt.plot(reward_history)
plt.title("Training Progress: REINFORCE with Baseline")
plt.xlabel("Episode")
plt.ylabel("Total Reward")
plt.grid(True)
plt.tight_layout()
plt.show()