# -*- coding: utf-8 -*-
"""perceptron.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vBkRx3zcZqLB5_Zuq6uHAsPLXGc655Hl
"""

"""
demo_script.py

Command-line script to train and evaluate the Stepwise Policy Gradient
agent on CartPole-v1 environment.

Usage:
    python demo_script.py
"""

import numpy as np
import tensorflow as tf
import gym
from stepwise_policy_gradient import StepwisePolicyGradientAgent, create_policy_network


def basic_policy(obs):
    """
    Hardcoded baseline policy:
    Accelerate left if pole angle < 0, else right.
    """
    angle = obs[2]
    return 0 if angle < 0 else 1


def evaluate_baseline_policy(env_name='CartPole-v1', n_episodes=500):
    env = gym.make(env_name)
    rewards = []
    for _ in range(n_episodes):
        obs = env.reset()
        done = False
        total_reward = 0
        while not done:
            action = basic_policy(obs)
            obs, reward, done, _ = env.step(action)
            total_reward += reward
        rewards.append(total_reward)
    env.close()
    rewards = np.array(rewards)
    print(f"Baseline Hardcoded Policy over {n_episodes} episodes:")
    print(f"  Mean Reward: {rewards.mean():.2f}")
    print(f"  Min Reward: {rewards.min()}, Max Reward: {rewards.max()}")
    print()
    return rewards


def main():
    seed = 42
    np.random.seed(seed)
    tf.random.set_seed(seed)

    env_name = 'CartPole-v1'
    n_iterations = 150
    n_episodes_per_update = 10
    n_max_steps = gym.make(env_name).spec.max_episode_steps

    print("Evaluating baseline hardcoded policy...")
    evaluate_baseline_policy(env_name, n_episodes=500)

    print("Initializing untrained policy network...")
    policy_net = create_policy_network(n_inputs=4)
    agent = StepwisePolicyGradientAgent(
        env_name=env_name,
        model=policy_net,
        loss_fn=tf.keras.losses.binary_crossentropy,
        optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),
        discount_factor=0.95,
        seed=seed
    )

    mean_reward_before, _ = agent.evaluate_policy(n_eval_episodes=50)
    print(f"Untrained policy average reward over 50 episodes: {mean_reward_before:.2f}\n")

    print("Training policy network using Stepwise Policy Gradient...")
    eval_rewards = agent.train(
        n_iterations=n_iterations,
        n_episodes_per_update=n_episodes_per_update,
        n_max_steps=n_max_steps
    )

    mean_reward_after, _ = agent.evaluate_policy(n_eval_episodes=50)
    print(f"\nTrained policy average reward over 50 episodes: {mean_reward_after:.2f}")

    print("\nTraining complete.")


if __name__ == "__main__":
    main()