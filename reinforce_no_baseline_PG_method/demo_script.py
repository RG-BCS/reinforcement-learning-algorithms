# -*- coding: utf-8 -*-
"""perceptron.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vBkRx3zcZqLB5_Zuq6uHAsPLXGc655Hl
"""

"""
demo_script.py

Run REINFORCE (no baseline) policy gradient training on CartPole-v1 environment.

Usage:
    python demo_script.py
"""

import numpy as np
import tensorflow as tf
from tensorflow import keras
import gym
import matplotlib.pyplot as plt

from reinforce_policy import (build_policy_network,evaluate_policy,train_policy_model)

def main():
    # Set random seeds for reproducibility
    seed = 65
    np.random.seed(seed)
    tf.random.set_seed(seed)

    env_name = "CartPole-v1"

    # Build policy model
    model = build_policy_network()

    # Define optimizer
    optimizer = keras.optimizers.Adam(learning_rate=0.01)

    # Create environment
    env = gym.make(env_name)

    # Evaluate untrained policy
    pretrain_reward = evaluate_policy(env, model)
    print(f"Reward before training: {pretrain_reward}")

    # Train the policy with REINFORCE
    episodes = 500
    reward_history = train_policy_model(
        env_name=env_name,
        model=model,
        optimizer=optimizer,
        episodes=episodes,
        gamma=0.99,
    )

    # Evaluate trained policy
    posttrain_reward = evaluate_policy(env, model)
    print(f"Reward after training: {posttrain_reward}")

    # Average over multiple runs
    test_runs = 20
    test_rewards = [evaluate_policy(env, model) for _ in range(test_runs)]
    print(f"Average reward over {test_runs} runs: {np.mean(test_rewards):.2f}")

    # Plot training progress
    plt.plot(reward_history)
    plt.xlabel("Episode")
    plt.ylabel("Total Reward")
    plt.title("REINFORCE Training Progress")
    plt.grid(True)
    plt.show()

if __name__ == "__main__":
    main()